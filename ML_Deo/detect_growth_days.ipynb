{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**IMPORT**",
   "id": "7e1fe6d78ddee0bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T04:51:11.774939Z",
     "start_time": "2024-06-02T04:51:00.292412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ],
   "id": "initial_id",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T04:51:18.541901Z",
     "start_time": "2024-06-02T04:51:18.536702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_series(data, min, max):\n",
    "    data-=min\n",
    "    data/=max\n",
    "    return data\n",
    "\n",
    "def windowed_dataset(series, batch_size, n_past=24, n_future=4, shift=1):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(size=n_past+n_future, shift=shift, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(n_past+n_future))\n",
    "    ds = ds.shuffle(1000)\n",
    "    ds = ds.map(lambda w: (w[:-n_future], w[-n_future:, :1]))\n",
    "    ds = ds.batch(batch_size).prefetch(shift)\n",
    "    return ds"
   ],
   "id": "1bb146c77386f190",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T05:39:01.124426Z",
     "start_time": "2024-06-02T05:35:30.360743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Retrieve dataset\n",
    "df = pd.read_csv(os.path.join('lettuce_growth_days', 'lettuce_dataset.csv'), sep=',', encoding='ISO-8859-1')\n",
    "\n",
    "# Delete column date, plant_id\n",
    "df = df.drop(columns=['Plant_ID', 'Date'])\n",
    "\n",
    "# Number of features in dataset\n",
    "N_FEATURES = df.shape[1]\n",
    "\n",
    "print(df.head())\n",
    "print(F'n features: {N_FEATURES}')\n",
    "\n",
    "# Normalize data\n",
    "data = df.values\n",
    "split_time = int(len(data)*0.8)\n",
    "test = int(len(data)*0.9)\n",
    "data = normalize_series(data, data.min(axis=0), data.max(axis=0))\n",
    "\n",
    "x_train = data[:split_time]\n",
    "print(f'Train: {len(x_train)}')\n",
    "x_valid = data[split_time:test]\n",
    "print(f'Valid: {len(x_valid)}')\n",
    "x_test = data[test:]\n",
    "print(f'Test: {len(x_test)}')\n",
    "\n",
    "# DO NOT CHANGE THIS\n",
    "BATCH_SIZE = 32\n",
    "N_PAST = 24  # Number of past time steps based on which future observations should be predicted\n",
    "N_FUTURE = 24  # Number of future time steps which are to be predicted.\n",
    "SHIFT = 1  # By how many positions the window slides to create a new window of observations.\n",
    "\n",
    "# Code to create windowed train and validation datasets.\n",
    "# Complete the code in windowed_dataset.\n",
    "# YOUR CODE HERE\n",
    "train_set = windowed_dataset(series=x_train, batch_size=BATCH_SIZE, n_past=N_PAST, n_future=N_FUTURE, shift=SHIFT)\n",
    "# YOUR CODE HERE\n",
    "valid_set = windowed_dataset(series=x_valid, batch_size=BATCH_SIZE, n_past=N_PAST, n_future=N_FUTURE, shift=SHIFT)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(64, 'relu', return_sequences=True, input_shape=[N_PAST, N_FEATURES]),\n",
    "    # tf.keras.layers.Dense(64, input_shape=(N_PAST, N_FEATURES)),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.Dense(32),\n",
    "    \n",
    "    tf.keras.layers.Dense(N_FUTURE, 'linear'),\n",
    "])\n",
    "\n",
    "class StopWhenReachDesireMAE(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, monitor='mae', monitor2='val_mae', target=0.14):\n",
    "        super(StopWhenReachDesireMAE, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.monitor2 = monitor2\n",
    "        self.target = target\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        current2 = logs.get(self.monitor2)\n",
    "        if current is not None and current2 is not None:\n",
    "            if current < self.target and current2 < self.target:\n",
    "                print(\n",
    "                    f'\\nEpoch {epoch + 1}: {self.monitor} and {self.monitor2} have reached {self.target}. Stopping training.')\n",
    "                self.model.stop_training = True\n",
    "\n",
    "stop_callback = StopWhenReachDesireMAE('mae', 'val_mae', 0.05)\n",
    "\n",
    "# Code to train and compile the model\n",
    "# YOUR CODE HERE\n",
    "model.compile(\n",
    "    loss='mae',\n",
    "    optimizer='adam',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_set,\n",
    "    epochs=60,\n",
    "    validation_data=valid_set,\n",
    "    callbacks=[stop_callback]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(valid_set)\n",
    "print(f'Mean Absolute Error on validation data: {mae}')\n",
    "\n",
    "# Prepare test set for prediction\n",
    "test_set = windowed_dataset(series=x_test, batch_size=BATCH_SIZE, n_past=N_PAST, n_future=N_FUTURE, shift=SHIFT)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(test_set)\n",
    "\n",
    "# Flatten predictions for easier comparison\n",
    "y_pred_flat = y_pred.reshape(-1)\n",
    "\n",
    "# Extract actual values for comparison\n",
    "# Note: This step assumes you have the actual future values in x_test for comparison\n",
    "# Adjust based on your data's actual structure\n",
    "x_test_flat = []\n",
    "for window in windowed_dataset(x_test, BATCH_SIZE, N_PAST, N_FUTURE, SHIFT):\n",
    "    x_test_flat.extend(window[1].numpy().flatten())\n",
    "\n",
    "# Ensure the lengths match\n",
    "min_length = min(len(x_test_flat), len(y_pred_flat))\n",
    "x_test_flat = x_test_flat[:min_length]\n",
    "y_pred_flat = y_pred_flat[:min_length]\n",
    "\n",
    "# Optional: Convert predictions and actual values to a more readable format\n",
    "results = pd.DataFrame({'Actual': x_test_flat, 'Predicted': y_pred_flat})\n",
    "print(results.head())"
   ],
   "id": "a74762101558586c",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T05:41:56.824050Z",
     "start_time": "2024-06-02T05:41:05.452553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(os.path.join('lettuce_growth_days', 'lettuce_dataset.csv'), sep=',', encoding='ISO-8859-1')\n",
    "\n",
    "# Convert 'Date' to numerical values if necessary\n",
    "data['Date'] = pd.to_datetime(data['Date']).map(pd.Timestamp.toordinal)\n",
    "\n",
    "# Normalize the input features\n",
    "features = ['Date', 'Temperature (Â°C)', 'TDS Value (ppm)', 'pH Level']\n",
    "target = 'Growth Days'\n",
    "\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, monitor='mae', monitor1='val_mae', target=0.1):\n",
    "        super(CustomCallback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.monitor1 = monitor1\n",
    "        self.target = target\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs[self.monitor] is not None and logs[self.monitor1] is not None:\n",
    "            if logs[self.monitor] < self.target and logs[self.monitor1] < self.target:\n",
    "                print(f'\\n{self.monitor}: {logs[self.monitor]} < {self.target}')\n",
    "                print(f'\\n{self.monitor1}: {logs[self.monitor1]} < {self.target}')\n",
    "                self.model.stop_training = True\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='linear')  # Linear activation for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "cust_callbacks = CustomCallback(monitor='mae', target=0.045)\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=1000, validation_split=0.2, batch_size=32, callbacks=[cust_callbacks])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f'Mean Absolute Error on test data: {mae}')\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Optional: Convert predictions and actual values to a more readable format\n",
    "results = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred.flatten()})\n",
    "print(results.head())"
   ],
   "id": "b607e1ab758c6079",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T05:41:56.985024Z",
     "start_time": "2024-06-02T05:41:56.825051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f'Mean Absolute Error on test data: {mae}')\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Optional: Convert predictions and actual values to a more readable format\n",
    "results = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred.flatten()})\n",
    "print(results.head())"
   ],
   "id": "7eae018d3723f985",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T05:42:53.667462Z",
     "start_time": "2024-06-02T05:42:53.664343Z"
    }
   },
   "cell_type": "code",
   "source": "print(y_test)",
   "id": "9d5fc5f2bd4366bf",
   "execution_count": 12,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
